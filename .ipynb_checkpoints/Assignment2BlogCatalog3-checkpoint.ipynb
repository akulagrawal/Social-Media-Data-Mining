{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mCtauVwVNCoy"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import math\n",
    "from scipy.sparse import csc_matrix\n",
    "import random\n",
    "import operator\n",
    "import scipy.io\n",
    "import collections\n",
    "import heapq\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 4, 4\n",
    "subSize=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fvcCCCBXNCo5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data = open('edges.csv', \"r\")\n",
    "Graphtype = nx.Graph()\n",
    "\n",
    "G = nx.parse_edgelist(Data, comments='t', delimiter=',', create_using=Graphtype,\n",
    "                      nodetype=int, data=(('weight', float),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take subgraph for less computations\n",
    "# sub_edges=random.sample(list(diG.edges()),subSize) <-- wrong as it definitely loses properties of original graph\n",
    "# G=nx.Graph(sub_edges)\n",
    "G.remove_edges_from(G.selfloop_edges())\n",
    "\n",
    "\n",
    "# the one-fold of YES edges\n",
    "total_edges=list(G.edges())\n",
    "np.random.shuffle(total_edges)\n",
    "l=int(len(total_edges)*0.7) # keep 70% graph, 30% for growth labels\n",
    "# edges_0 exist only for common neighbors\n",
    "edges_0,ETEs = total_edges[:l], total_edges[l:]\n",
    "\n",
    "\"\"\"\n",
    " Use all the edges present in the network as \"YES\", and randomly choose equal number of \"Non-existing\" edges as \"NO\". \n",
    "\"\"\"\n",
    "# Randomly choose equal sized (entire)fold of NO edges\n",
    "nonETEs=random.sample(list(nx.non_edges(G)),len(ETEs))\n",
    "total_edges=ETEs+nonETEs #total in consideration\n",
    "\n",
    "xe,nxe=len(ETEs),len(nonETEs)\n",
    "methods=['CN','JC','AA','RA','PA']\n",
    "\n",
    "## \n",
    "## NOTE: HAVENT CHECKED FOR CONNECTIVITY MAINTAINED.\n",
    "# len(nx.bfs_tree(G,nodelist[0]).edges())\n",
    "# # extract matrix in order, and convert to dense representation\n",
    "# A = nx.adjacency_matrix(G, nodelist=nodelist).todense()\n",
    "N=G.number_of_nodes()\n",
    "# store index for node index\n",
    "nodelist = list(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 10312\n",
      "Number of edges: 333983\n",
      "Average degree:  64.7756\n",
      "10312\n",
      "333983\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(G))\n",
    "print(nx.number_of_nodes(G))\n",
    "print(nx.number_of_edges(G))\n",
    "print(nx.is_directed(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nonedges(G,u):  #a generator with (u,v) for every non neighbor v\n",
    "    for v in nx.non_neighbors(G, u):\n",
    "        yield (u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for u in G.nodes():\n",
    "    adar = nx.adamic_adar_index(G,nonedges(G,u))\n",
    "    for v in nx.non_neighbors(G, u):\n",
    "        com = nx.common_neighbors(G,u,v)\n",
    "    jac = nx.jaccard_coefficient(G,nonedges(G,u))\n",
    "    res = nx.resource_allocation_index(G,nonedges(G,u))\n",
    "    pre = nx.preferential_attachment(G,nonedges(G,u))\n",
    "#     tenlargest = heapq.nlargest(10, pred, key = lambda x: x[2])\n",
    "#     print(tenlargest)\n",
    "#     for u,v,p in pred:\n",
    "#         print(u,v,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allm={m:{} for m in methods}\n",
    "toponame=\"dataset\"+\".csv\"\n",
    "with open(toponame,\"w\",newline=\"\", encoding=\"utf-8\") as f:   # binary mode for windows \\r\\n prob\n",
    "    writer = csv.writer(f, delimiter=',')        \n",
    "    writer.writerow(['node1','node2']+methods+['label'])\n",
    "\n",
    "#     for i,n1 in enumerate(nodelist):\n",
    "#         for j,n2 in enumerate(nodelist):\n",
    "#             if(i==j):\n",
    "#                 continue\n",
    "    for p in total_edges:\n",
    "            n1,n2=p\n",
    "            ngh1 = set(G[n1])\n",
    "            ngh2 = set(G[n2])\n",
    "            inter = ngh1.intersection(ngh2) # ngh1 & ngh2\n",
    "            inter_l = len(inter)\n",
    "            union_l = len(ngh1.union(ngh2)) #ngh1 | ngh2            \n",
    "            \n",
    "            allm['CN'][p]=inter_l\n",
    "            allm['JC'][p]=(inter_l/union_l) if union_l else 0.0\n",
    "            allm['AA'][p]=sum([1/log(len(G[z])) for z in inter]) # denom cant be zero as atleast 2 edges\n",
    "            allm['RA'][p]=sum([1/len(G[z]) for z in inter])\n",
    "            allm['PA'][p]=len(ngh1)*len(ngh2)\n",
    "            \n",
    "            # + can add your own features\n",
    "            writer.writerow(list(p) + [allm[m][p] for m in methods] + [1 if G.has_edge(n1,n2) else 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library & dataset\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv(toponame)\n",
    "df=df[methods]\n",
    "# df.describe()\n",
    "# Basic correlogram\n",
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in methods:\n",
    "    plt.subplots()\n",
    "    plt.xlabel(m)\n",
    "    df[m].hist(align='mid',bins=[0,20,40,60,80,])#plot(kind='kde')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(df):\n",
    "    from matplotlib import pyplot as plt\n",
    "    from matplotlib import cm as cm\n",
    "\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    cmap = cm.get_cmap('jet', 30)\n",
    "    cax = ax1.imshow(df.corr(), interpolation=\"nearest\", cmap=cmap)\n",
    "    ax1.grid(axis='both')\n",
    "    labels=['X']+methods\n",
    "    ax1.set_xticklabels(labels,fontsize=26)\n",
    "    ax1.set_yticklabels(labels,fontsize=26)\n",
    "    # Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
    "    fig.colorbar(cax, ticks=list([x/100 for x in range(0,100,5)]))\n",
    "    plt.show()\n",
    "\n",
    "print(df.corr())\n",
    "correlation_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#precision and recall for topological algorithms#\n",
    "def precision_recall(score_labels, k):\n",
    "    l=len(score_labels)\n",
    "    thresh = score_labels[int(l*k)][0]           #all above threshold will have greater cn/jj/aa value. so, label should be 1\n",
    "    truepos = 0\n",
    "    falsepos = 0\n",
    "    falseneg=0\n",
    "    trueneg =0\n",
    "    for i in range(0, l):\n",
    "        if(score_labels[i][1]==1 and score_labels[i][0]>=thresh):\n",
    "            truepos+=1\n",
    "        elif (score_labels[i][1]==0 and score_labels[i][0]>=thresh):\n",
    "            falsepos+=1\n",
    "        if(score_labels[i][1]==0 and score_labels[i][0]<=thresh):\n",
    "            trueneg+=1\n",
    "        elif(score_labels[i][1]==1 and score_labels[i][0]<=thresh):\n",
    "            falseneg+=1\n",
    "    \n",
    "    truepos = float(truepos)\n",
    "    trueneg = float(trueneg)\n",
    "    falsepos = float(falsepos)\n",
    "    falseneg = float(falseneg)\n",
    "    p = '%.3f'%float(truepos/(truepos+falsepos))\n",
    "    r = '%.3f'%float(truepos/(truepos+falseneg))\n",
    "    return [p,r]\n",
    "\n",
    "all_edges_score,nonExisting={},{}\n",
    "for m in methods:\n",
    "    nonExisting[m] = sorted([(e,allm[m][e]) for e in nonETEs],key=lambda x:x[1])\n",
    "    all_edges_score[m] = sorted([(allm[m][e],1) for e in ETEs]+[(allm[m][e],0) for e in nonETEs],key=lambda x:x[0],reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges_score['CN'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "For AUC: \n",
    "for two node pairs p1,p2 \n",
    "AUC = P( p1.score > p2.score and p1 is existing and p2 is non-existing )\n",
    "above value is averaged over all node pairs\n",
    "\"\"\"\n",
    "# for name,edges in zip([\"metrics_for_existing\"+\".csv\",\"metrics_for_nonexisting\"+\".csv\"],[edgelist,nonedgelist]):\n",
    "topoaucname=\"topological_metrics\"+\".csv\"\n",
    "\"\"\"\n",
    "AvgAUC =(n1 + 0.5n2)/n ∗ p\n",
    "where \n",
    "n1 = number of times link prediction score for existing test edge is greater than other non-existing test edges, \n",
    "n2 = number of times link prediction score for existing test edge is equal to other non-existing test edges,\n",
    "n = number of non-existing test edges, and p = number of existing test edges.\n",
    "\"\"\"\n",
    "# Source for formula: https://docs.google.com/viewer?a=v&pid=sites&srcid=ZGVmYXVsdGRvbWFpbnxha2FzaGFuaWwyNjAxfGd4OjI5Y2ExYmExMGI0OWE0ODc\n",
    "with open(topoaucname,\"w\",newline=\"\", encoding=\"utf-8\") as f:   # binary mode for windows \\r\\n prob\n",
    "    writer = csv.writer(f, delimiter=',')        \n",
    "    writer.writerow(['node1','node2']+methods)\n",
    "    sumAUC={m:0 for m in methods}\n",
    "    total={m:0 for m in methods}\n",
    "    for p in ETEs:\n",
    "        row=[p[0],p[1]]\n",
    "        \n",
    "        for m in methods:        \n",
    "            score=allm[m][p]\n",
    "            count=0.0\n",
    "            for s in nonExisting[m]:\n",
    "                if(s[1]<score):\n",
    "                    count+=1.0\n",
    "                elif(s[1]==score):\n",
    "                    count+=0.5\n",
    "                else:\n",
    "                    break\n",
    "            local_auc = count/nxe\n",
    "            sumAUC[m]+=local_auc            \n",
    "            total[m]+=1\n",
    "            row.append(local_auc)\n",
    "            \n",
    "        writer.writerow(row)\n",
    "    row=['overall AUC','-']\n",
    "    row2=['PR@25%','-']\n",
    "    row3=['PR@50%','-']\n",
    "    row4=['PR@75%','-']\n",
    "    for m in methods:\n",
    "        assert(total[m]==xe)\n",
    "        row.append(sumAUC[m]/xe) # avg \n",
    "        row2.append(precision_recall(all_edges_score[m],k=0.25))\n",
    "        row3.append(precision_recall(all_edges_score[m],k=0.50))\n",
    "        row4.append(precision_recall(all_edges_score[m],k=0.75))\n",
    "    print(row)\n",
    "    writer.writerow(row)\n",
    "    print(row2)\n",
    "    writer.writerow(row2)\n",
    "    print(row3)\n",
    "    writer.writerow(row3)\n",
    "    print(row4)\n",
    "    writer.writerow(row4)\n",
    "\n",
    "#  If time: do Precision@K\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.genfromtxt(toponame, delimiter=',',skip_header=1)\n",
    "\n",
    "for m in range(2,2+len(methods)):\n",
    "    print(m,df[2:,m].max())\n",
    "    df[2:,m] = df[2:,m] / df[2:,m].max()\n",
    "x=df[:,2:-1]\n",
    "y=df[:,-1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "def reportClassifier(name,y_test,y_pred,scores=None):\n",
    "    print(\"\\n\\t\\t\"+name)\n",
    "    if(scores is not None):\n",
    "        print(\"\\nCross Validation Scores\")\n",
    "        print(scores)\n",
    "    print(\"\\nAccuracy: \",accuracy_score(y_test,y_pred))\n",
    "    print(\"\\nClassification Report\")\n",
    "    print(classification_report(y_test,y_pred))    \n",
    "    print(\"\\nConfusion Matrix\")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    try:\n",
    "        print(\"\\nROC AUC score\")\n",
    "        print(roc_auc_score(y_test, y_pred))\n",
    "    except ValueError:\n",
    "        print(\"Warning: Only one class in this fold\")\n",
    "\n",
    "def mean(x):\n",
    "    return sum(x)/float(len(x))\n",
    " \n",
    "def stddev(x):\n",
    "    if(len(x)<2):\n",
    "        return -1;\n",
    "    avg = mean(x)\n",
    "    variance = sum([pow(x-avg,2) for x in x])/float(len(x)-1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "def getFeatureProbability(x, mean, stddev):\n",
    "    if(stddev==0):# spike in gaussian\n",
    "        return 1 if x==mean else 0\n",
    "    exp = math.exp(-1*( math.pow(x-mean,2) / (2*math.pow(stddev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stddev)) * exp\n",
    "\n",
    "def splitByLabel(x,y):\n",
    "    yes,no=[],[]\n",
    "    for i in range(len(y)):\n",
    "        if(y[i]):\n",
    "            yes.append(x[i,:])\n",
    "        else:\n",
    "            no.append(x[i,:])\n",
    "    return yes,no\n",
    "\n",
    "def getMeanStds(x_train):\n",
    "    mean_stds=[]\n",
    "    for i in range(len(x_train[0])): # 5 times\n",
    "        mean_stds.append((mean(x_train[i]),stddev(x_train[i])))\n",
    "    return mean_stds\n",
    "\n",
    "\n",
    "def naive_bayes_gaussian(x_train,y_train):    \n",
    "    h,w=x_train.shape\n",
    "    labelYes,labelNo= splitByLabel(x_train,y_train)\n",
    "    # Train part:\n",
    "    yes_mean_stds=getMeanStds(labelYes)\n",
    "    no_mean_stds=getMeanStds(labelNo)\n",
    "    return yes_mean_stds,no_mean_stds\n",
    "\n",
    "def predict_naive_bayes(x_test,yms,nms):    \n",
    "    h,w=x_test.shape\n",
    "    y_pred=[]\n",
    "    #     p(Ci)\n",
    "    p=len(yms)/(len(yms)+len(nms))\n",
    "    # test part\n",
    "    for i in range(h):\n",
    "        x=x_test[i]\n",
    "        p_yes,p_no=p,1-p\n",
    "        for j in range(w): # 5 times\n",
    "            m,s=yms[j]\n",
    "            nm,ns=nms[j]\n",
    "            p_yes *= getFeatureProbability(x[j],m,s)\n",
    "            p_no *= getFeatureProbability(x[j],nm,ns)\n",
    "        if(p_yes>=p_no):\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                \n",
    "\n",
    "# For classifers: make five-folds\n",
    "# foldSize=xe//5\n",
    "# edge_folds = [ETEs[i*foldSize:(i+1)*foldSize] if i<4 else ETEs[i*foldSize:] for i in range(0,5)]\n",
    "# nonedge_folds = [ETEs[i*foldSize:(i+1)*foldSize] if i<4 else ETEs[i*foldSize:] for i in range(0,5)]\n",
    "\n",
    "kf=KFold(n_splits=5,shuffle=True)\n",
    "# for i in range(0,5):\n",
    "for train_index, test_index in kf.split(x):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    yes_mean_stds,no_mean_stds = naive_bayes_gaussian(x_train,y_train)\n",
    "    y_pred = predict_naive_bayes(x_test,yes_mean_stds,no_mean_stds)\n",
    "    reportClassifier(\"GaussianUD\",y_test,y_pred)\n",
    "\n",
    "    #for trial-\n",
    "    b=GaussianNB()\n",
    "    b.fit(x_train,y_train)\n",
    "    y_pred=b.predict(x_test)\n",
    "    reportClassifier(\"GaussianNB\",y_test,y_pred)\n",
    "    \n",
    "#     b=MultinomialNB()\n",
    "#     b.fit(x_train,y_train)\n",
    "#     y_pred=b.predict(x_test)\n",
    "#     reportClassifier(\"MultinomialNB\",y_test,y_pred)\n",
    "    \n",
    "#     b=BernoulliNB(binarize=True)\n",
    "#     b.fit(x_train,y_train)\n",
    "#     y_pred=b.predict(x_test)\n",
    "#     reportClassifier(\"BernoulliNB\",y_test,y_pred)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    svclassifier = SVC(kernel='linear')  \n",
    "    svclassifier.fit(x_train, y_train)\n",
    "    scores = cross_val_score(svclassifier,x, y, cv=5)\n",
    "    y_pred = svclassifier.predict(x_test)\n",
    "    reportClassifier(\"SVM\",y_test,y_pred,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    clf = tree.DecisionTreeClassifier()\n",
    "    scores = cross_val_score(clf,x, y, cv=5)\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    reportClassifier(\"Decision Tree\",y_test,y_pred,scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "imdb.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
